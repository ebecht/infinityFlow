utils::globalVariables(c("yvar", "chans"))

#' Wrapper to XGBoost training. Defined separetely to avoid passing too many objects in parLapplyLB
#' @param x passed from fit_regressions
#' @param params passed from fit_regressions
#' @importFrom stats predict
#' @export
#' @return A list with two elements: predictions and a fitted model
#' @examples
#' fitter_xgboost()
fitter_xgboost <- function(x = NULL, params = NULL){
    if(!requireNamespace("xgboost", quietly = TRUE)){
        stop("Please run install.packages(\"xgboost\")")
    }

    if(!is.null(x) & !is.null(params)){
        w <- x[,"train_set"]==1
        args <- c(list(data = x[w, chans], label = x[w, yvar], nthread = 1L, verbose = 0), params)
        model <- do.call(xgboost::xgboost, args)
        pred <- predict(model, x[, chans])
        rm(list=setdiff(ls(),c("pred","model")))
        return(list(pred=pred,model=model))
    }
}

#' Train XGBoost regressions
#' @param yvar name of the exploratory measurement
#' @param params Named list of arguments passed to regression fitting functions
#' @param paths Character vector of paths to store intput, intermediary results, outputs...
#' @param cores Number of cores to use for parallel computing
#' @param chans vector of backbone channels' names
#' @param regression_functions named list of fitter_* functions, passed from infinity_flow()
#' @param verbose Verbosity
#' @noRd
#' @importFrom xgboost xgb.save.raw
#' @importFrom xgboost xgb.load.raw
#' @importFrom xgboost xgb.DMatrix
fit_regressions <- function(
                            yvar,
                            params,
                            paths,
                            cores,
                            chans=readRDS(file.path(paths["rds"],"chans.Rds")),
                            annot=read.table(paths["annotation"],sep=",",header=TRUE,stringsAsFactors=FALSE),
                            regression_functions,
                            verbose=TRUE
                            )
{   
    if(verbose){
        message("Fitting regression models")
    }
    
    if(verbose){
        message("\tTraining models on 50% of the input data")
    }

    t0 <- Sys.time()

    models <- list()
    timings <- numeric()

    pb <- txtProgressBar(min = 0, max = nrow(annot), style = 1, width = 50)
    for(i in seq_len(nrow(annot))){
        xp <- h5read(file = paths["h5"], name = paste0("/input/expression_transformed_scaled/", i))
        colnames(xp) <- h5readAttributes(file = paths["h5"], name = paste0("/input/expression/", i))$colnames
        
        w <- sample(rep(c(1L,0L), times = c(floor(nrow(xp)/2), nrow(xp) - floor(nrow(xp)/2))))
        h5write(file = paths["h5"], name = paste0("/sampling/fitting/", i), obj = w)

        args <- c(list(data = xp[w == 1L, chans], label = xp[w == 1L, yvar], nthread = cores, verbose = 0), params)
        model <- do.call(xgboost::xgboost, args)
        models[[i]] = model
        setTxtProgressBar(pb, i)
    }
    close(pb)

    t1 <- Sys.time()
    dt <- difftime(t1,t0,units="secs")
    cat("\t",dt," seconds","\n",sep="")
    timings <- c(timings,dt)
    
    if(verbose){
        message("\tGenerating intra-well predictions for train and test sets")
    }
    pb <- txtProgressBar(min = 0, max = nrow(annot), style = 1, width = 50)
    for(i in seq_len(nrow(annot))){
        xp <- h5read(file = paths["h5"], name = paste0("/input/expression_transformed_scaled/", i))
        colnames(xp) <- h5readAttributes(file = paths["h5"], name = paste0("/input/expression/", i))$colnames
        preds <- predict(models[[i]], xp[, chans])
        h5write(file = paths["h5"], name = paste0("/predictions/intra_well/", i), obj = preds)
        setTxtProgressBar(pb, i)
    }
    close(pb)
    models <- lapply(models, xgb.save.raw)
    saveRDS(models,file=file.path(paths["rds"],"regression_models.Rds"))
    list(timings=timings)
}

#' Predict missing measurements using fitted regressions
#' @param paths Character vector of paths to store intput, intermediary results, outputs...
#' @param prediction_events_downsampling Number of events to predict data for per file
#' @param cores Number of cores to use for parallel computing
#' @param chans vector of backbone channels' names
#' @param events.code vector of length nrow(xp) specifying from which well each event originates
#' @param xp Logicle-transformed backbone expression matrix
#' @param models list of list of machine learning models, created by infinityFlow:::fit_regressions
#' @param train_set data.frame with nrow(xp) rows, specifying which events were used to train the models. Generated by infinityFlow:::fit_regressions
#' @param regression_functions named list of fitter_* functions, passed from infinity_flow()
#' @param neural_networks_seed Seed for computational reproducibility when using neural networks. Passed from infinity_flow()
#' @param verbose Verbosity
#' @importFrom xgboost xgb.parameters<-
#' @noRd
predict_from_models <- function(
                                paths,
                                prediction_events_downsampling,
                                cores,
                                chans=readRDS(file.path(paths["rds"],"chans.Rds")),
                                models=readRDS(file.path(paths["rds"],"regression_models.Rds")),
                                verbose=TRUE,
                                annot=read.table(paths["annotation"],sep=",",header=TRUE,stringsAsFactors=FALSE)
                                )
{   
    if(verbose){
        message("Imputing missing measurements")
    }

    if(verbose){
        message("\tGenerating predicted expression levels for up to ", prediction_events_downsampling, " events per file")
    }

    for(i in seq_len(nrow(annot))){
        train_set <- h5read(paths["h5"], paste0("/sampling/fitting/", i))
        w <- train_set == 0L
        pred_set = rep(0L, length(train_set))
        pred_set[w][sample(seq_len(sum(w)),min(prediction_events_downsampling,sum(w)))] <- 1L
        h5write(file = paths["h5"], name = paste0("/sampling/predictions/", i), obj = pred_set)
    }

    if(verbose){
        message("\tImputing...")
    }
    models = lapply(models, function(x){xgb.load.raw(x)})
    models = lapply(
        models,
        function(x){
            xgb.parameters(x)<-list(nthread=cores)
            x
        }
    )
    pb <- txtProgressBar(min = 0, max = nrow(annot), style = 1, width = 50)
    t0 <- Sys.time()
    for(i in seq_len(nrow(annot))){
        pred_set <- h5read(paths["h5"], paste0("/sampling/predictions/", i)) == 1L
        xp <- h5read(paths["h5"], paste0("/input/expression_transformed_scaled/", i))
        xp <- xp[pred_set, ]
        colnames(xp) <- h5readAttributes(file = paths["h5"], name = paste0("/input/expression/", i))$colnames
        xp <- xgb.DMatrix(xp[, chans])
        for(j in seq_along(models)){
            predictions <- predict(object = models[[j]], newdata = xp)
            h5write(predictions, paths["h5"], name = paste0("/predictions/raw/", i), index = list(NULL, j))
        }
        setTxtProgressBar(pb, i)
    }
    close(pb)
    
    t1 <- Sys.time()
    dt <- difftime(t1,t0,units="secs")
    cat("\t",dt," seconds","\n",sep="")
    
    list(timings=dt)
}
